{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WgehjBGdCx2"
   },
   "source": [
    "# BuzzBlog Experiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVNFVn5H2Ub8"
   },
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lBdMUmd1Cjn"
   },
   "outputs": [],
   "source": [
    "########## GENERAL\n",
    "# Environment (options: \"colab\", \"local\")\n",
    "ENV = \"local\"\n",
    "# Experiment directory name\n",
    "EXPERIMENT = \"BuzzBlogBenchmark_2021-03-18-14-14-16\"\n",
    "\n",
    "########## DIRECTORY STRUCTURE\n",
    "LOADGEN_NODE = \"apt087.apt.emulab.net\"\n",
    "LOADBALANCER_NODE = \"apt078.apt.emulab.net\"\n",
    "APIGATEWAY_NODE = \"apt078.apt.emulab.net\"\n",
    "ACCOUNT_SERVICE_NODE = \"apt083.apt.emulab.net\"\n",
    "ACCOUNT_DB_NODE = \"apt080.apt.emulab.net\"\n",
    "FOLLOW_SERVICE_NODE = \"apt083.apt.emulab.net\"\n",
    "LIKE_SERVICE_NODE = \"apt083.apt.emulab.net\"\n",
    "POST_SERVICE_NODE = \"apt083.apt.emulab.net\"\n",
    "POST_DB_NODE = \"apt080.apt.emulab.net\"\n",
    "UNIQUEPAIR_SERVICE_NODE = \"apt083.apt.emulab.net\"\n",
    "UNIQUEPAIR_DB_NODE = \"apt080.apt.emulab.net\"\n",
    "\n",
    "########## REQUEST LOGS\n",
    "# Fine-grained window to group PIT data\n",
    "PIT_FG_WINDOW_IN_MS = 50\n",
    "# Function to aggregate PIT data\n",
    "PIT_AGGREGATE_FUNC = \"max\"\n",
    "\n",
    "########## SYSTEM EVENT MONITORING LOGS\n",
    "##### TCPLIFE\n",
    "# Fine-grained window to group TCP connection lifespan\n",
    "TCPLIFE_FG_WINDOW_IN_MS = 25\n",
    "\n",
    "########## SYSTEM RESOURCE MONITORING LOGS\n",
    "##### COLLECTL\n",
    "# Fine-grained window to group Collectl measurements\n",
    "COLLECTL_FG_WINDOW_IN_MS = 50\n",
    "# Function to aggregate Collectl measurements\n",
    "COLLECTL_AGGREGATE_FUNC = \"max\"\n",
    "# CPU metric to be analyzed (options: \"user\", \"nice\", \"system\", \"wait\", \"irq\", \"soft\", \"steal\", \"idle\", \"total\", \"guest\", \"guest_n\", \"intrpt\")\n",
    "CPU_METRIC = \"total\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwwtkHfAdCx3"
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IO0_sXBqdCx3"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "import codecs\n",
    "import csv\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the environment\n",
    "if ENV == \"colab\":\n",
    "  from google.colab import drive\n",
    "  drive.mount(\"GoogleDrive\", force_remount=True)\n",
    "  EXPERIMENT_DIR = os.path.join(\"GoogleDrive\", \"MyDrive\", EXPERIMENT)\n",
    "elif ENV == \"local\":\n",
    "  EXPERIMENT_DIR = EXPERIMENT\n",
    "\n",
    "# Load experiment metadata\n",
    "with open(os.path.join(EXPERIMENT_DIR, \"metadata.yml\")) as metadata_file:\n",
    "    metadata = yaml.load(metadata_file, Loader=yaml.Loader)\n",
    "\n",
    "# Load experiment configuration files\n",
    "with open(os.path.join(EXPERIMENT_DIR, \"conf\", \"system.yml\")) as system_conf_file:\n",
    "    system_conf = yaml.load(system_conf_file, Loader=yaml.Loader)\n",
    "with open(os.path.join(EXPERIMENT_DIR, \"conf\", \"workload.yml\")) as workload_conf_file:\n",
    "    workload_conf = yaml.load(workload_conf_file, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml.dump(metadata, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3r4VXjPwdCx5"
   },
   "source": [
    "## Request Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sytpElWWdCx5"
   },
   "outputs": [],
   "source": [
    "# Parse request logs\n",
    "REQUEST_LOG_PATTERN = r\"^\\[(\\d+\\-\\d+\\-\\d+ \\d+:\\d+:\\d+.\\d+)\\] (.+) (.+) (\\d+) - latency=(\\d+.\\d+)$\"\n",
    "URL_PATTERN = r\"^http://[\\w\\.]+:\\d+/{path}/?\\??{qs}$\"\n",
    "REQUEST_TO_TYPE = {\n",
    "    (URL_PATTERN.format(path=\"account\", qs=\"\"), \"POST\"): \"create_account\",\n",
    "    (URL_PATTERN.format(path=\"account/\\d+\", qs=\"\"), \"PUT\"): \"update_account\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"\"), \"POST\"): \"create_post\",\n",
    "    (URL_PATTERN.format(path=\"post/\\d+\", qs=\"\"), \"DELETE\"): \"delete_post\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"\"), \"POST\"): \"follow_account\",\n",
    "    (URL_PATTERN.format(path=\"follow/\\d+\", qs=\"\"), \"DELETE\"): \"delete_follow\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"\"), \"POST\"): \"like_post\",\n",
    "    (URL_PATTERN.format(path=\"like/\\d+\", qs=\"\"), \"DELETE\"): \"delete_like\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"\"), \"GET\"): \"retrieve_recent_posts\",\n",
    "    (URL_PATTERN.format(path=\"post/\\d+\", qs=\"\"), \"GET\"): \"retrieve_post\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"post_id=\\d+\"), \"GET\"): \"retrieve_post_likes\",\n",
    "    (URL_PATTERN.format(path=\"account/\\d+\", qs=\"\"), \"GET\"): \"retrieve_account\",\n",
    "    (URL_PATTERN.format(path=\"post\", qs=\"author_id=\\d+\"), \"GET\"): \"retrieve_account_posts\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"followee_id=\\d+\"), \"GET\"): \"retrieve_account_followers\",\n",
    "    (URL_PATTERN.format(path=\"follow\", qs=\"follower_id=\\d+\"), \"GET\"): \"retrieve_account_followees\",\n",
    "    (URL_PATTERN.format(path=\"like\", qs=\"account_id=\\d+\"), \"GET\"): \"retrieve_account_likes\"\n",
    "}\n",
    "requests = []\n",
    "tarball = tarfile.open(os.path.join(EXPERIMENT_DIR, \"logs\", LOADGEN_NODE, \"loadgen.tar.gz\"))\n",
    "with tarball.extractfile(\"./loadgen.log\") as loadgen_log_file:\n",
    "  for request_log in loadgen_log_file:\n",
    "    timestamp, method, url, status_code, latency = re.match(REQUEST_LOG_PATTERN, request_log.decode(\"utf-8\")).groups()\n",
    "    requests.append({\"timestamp\": pd.to_datetime(timestamp), \"method\": method, \"url\": url,\n",
    "                     \"status_code\": int(status_code), \"latency\": float(latency)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSCD-s9ydCx5"
   },
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "requests = pd.DataFrame(requests)\n",
    "requests.sort_values(by=\"timestamp\", ascending=True, inplace=True)\n",
    "requests[\"status\"] = requests.apply(lambda r: \"successful\" if r[\"status_code\"] == 200 else \"failed\", axis=1)\n",
    "requests[\"time\"] = requests.apply(lambda r: (r[\"timestamp\"] - requests[\"timestamp\"].min()).total_seconds(), axis=1)\n",
    "requests[\"window\"] = requests.apply(lambda r: int(r[\"time\"]), axis=1)\n",
    "requests[\"fg_window\"] = requests.apply(lambda r: int(r[\"time\"] * 1000) // PIT_FG_WINDOW_IN_MS, axis=1)\n",
    "requests[\"type\"] = requests.apply(lambda r: [request_type\n",
    "    for ((pattern, method), request_type) in REQUEST_TO_TYPE.items()\n",
    "    if method == r[\"method\"] and re.match(pattern, r[\"url\"])][0], axis=1)\n",
    "requests[\"rw\"] = requests.apply(lambda r: \"read\" if r[\"method\"] == \"GET\" else \"write\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-7dBMEQdCx6"
   },
   "source": [
    "### Workload Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGoXzJdP-GRx"
   },
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GFb4w8ssPS-"
   },
   "outputs": [],
   "source": [
    "print(\"Number of requests\")\n",
    "print(\"  Total:       %7d\" % requests.shape[0])\n",
    "print(\"  Status\")\n",
    "print(\"    Failed:    %7d (%9.5f%%)\" % (requests[requests[\"status\"] == \"failed\"][\"status\"].count(), (requests[requests[\"status\"] == \"failed\"][\"status\"].count() / requests.shape[0]) * 100))\n",
    "print(\"    Succesful: %7d (%9.5f%%)\" % (requests[requests[\"status\"] == \"successful\"][\"status\"].count(), (requests[requests[\"status\"] == \"successful\"][\"status\"].count() / requests.shape[0]) * 100))\n",
    "print(\"  Type\")\n",
    "print(\"    Read:      %7d (%9.5f%%)\" % (requests[requests[\"rw\"] == \"read\"][\"rw\"].count(), (requests[requests[\"rw\"] == \"read\"][\"rw\"].count() / requests.shape[0]) * 100))\n",
    "print(\"    Write:     %7d (%9.5f%%)\" % (requests[requests[\"rw\"] == \"write\"][\"rw\"].count(), (requests[requests[\"rw\"] == \"write\"][\"rw\"].count() / requests.shape[0]) * 100))\n",
    "print(\"Experiment duration (s)\")\n",
    "print(\"  Total:       %7.3f\" % requests[\"time\"].max())\n",
    "print(\"  Ramp\")\n",
    "print(\"    Up:        %7.3f (%9.5f%%)\" % (workload_conf[\"duration\"][\"ramp_up\"], (workload_conf[\"duration\"][\"ramp_up\"] / requests[\"time\"].max()) * 100))\n",
    "print(\"    Down:      %7.3f (%9.5f%%)\" % (workload_conf[\"duration\"][\"ramp_down\"], (workload_conf[\"duration\"][\"ramp_down\"] / requests[\"time\"].max()) * 100))\n",
    "print(\"Latency (ms)\")\n",
    "print(\"  P99:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.99) * 1000))\n",
    "print(\"  P95:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.95) * 1000))\n",
    "print(\"  P50:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.50) * 1000))\n",
    "print(\"  Avg:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].mean() * 1000))\n",
    "print(\"  Std:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].std() * 1000))\n",
    "print(\"Throughput (req/s)\")\n",
    "print(\"  P99:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0).quantile(0.99))\n",
    "print(\"  P95:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0).quantile(0.95))\n",
    "print(\"  P50:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0).quantile(0.59))\n",
    "print(\"  Avg:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0).mean())\n",
    "print(\"  Std:         %7.2f\" % requests.groupby([\"window\"])[\"window\"].count().reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xceJTrc5dCx6"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "# Number of read/write requests\n",
    "df = requests.groupby([\"rw\"]).count()[\"method\"]\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"Number of read/write requests\",\n",
    "        xlabel=\"\", ylabel=\"\",\n",
    "        legend=True)\n",
    "# Number of successful/failed requests\n",
    "df = requests.groupby([\"status\"]).count()[\"method\"]\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"Number of successful/failed requests\",\n",
    "        xlabel=\"\", ylabel=\"\",\n",
    "        legend=True)\n",
    "# HTTP status code of failed requests\n",
    "df = requests[requests[\"status\"] == \"failed\"].groupby([\"status_code\"]).count()[\"method\"]\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"HTTP status code of failed requests\",\n",
    "        xlabel=\"\", ylabel=\"\",\n",
    "        legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A52oXoXCdCx6"
   },
   "outputs": [],
   "source": [
    "df = requests.groupby([\"type\", \"status\"]).count()[\"method\"].unstack().fillna(0)\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "df.plot(ax=ax, kind=\"bar\", stacked=True, title=\"Number of requests of each type\",\n",
    "        xlabel=\"\", ylabel=\"Requests (count)\",\n",
    "        color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True,\n",
    "        grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CVyGUSedCx6"
   },
   "source": [
    "### Throughput (1-second window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMCoONkbdCx7"
   },
   "outputs": [],
   "source": [
    "df = requests.groupby([\"window\", \"status\"])[\"window\"].count().unstack().fillna(0)\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.axvline(x=workload_conf[\"duration\"][\"ramp_up\"],\n",
    "           ls=\"--\", color=\"green\")\n",
    "ax.axvline(x=workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"],\n",
    "           ls=\"--\", color=\"green\")\n",
    "df.plot(ax=ax, kind=\"bar\", stacked=True, title=\"Throughput (requests per second)\",\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"Requests (count)\",\n",
    "        color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True, grid=True,\n",
    "        xticks=range(0, int(requests[\"time\"].max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awJncDrWdCx7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 24))\n",
    "for (i, (request_type, _)) in enumerate(requests.groupby([\"type\"])):\n",
    "    df = requests[requests[\"type\"] == request_type]\n",
    "    df = df.groupby([\"window\", \"status\"])[\"window\"].count().unstack().fillna(0)\n",
    "    df = df.reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0)\n",
    "    ax = fig.add_subplot(4, 4, i + 1)\n",
    "    ax.axvline(x=workload_conf[\"duration\"][\"ramp_up\"],\n",
    "               ls=\"--\", color=\"green\")\n",
    "    ax.axvline(x=workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"],\n",
    "               ls=\"--\", color=\"green\")\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"bar\", stacked=True, title=request_type,\n",
    "            xlabel=\"\", ylabel=\"\",\n",
    "            color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=False, grid=True,\n",
    "            xticks=range(0, int(requests[\"time\"].max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-gKDgEnq7cc"
   },
   "source": [
    "### Throughput (fine-grained window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hptIluSJrAoE"
   },
   "outputs": [],
   "source": [
    "# [CONFIG] Request type or '*' for all\n",
    "REQUEST_TYPE = '*'\n",
    "\n",
    "df = requests[requests[\"type\"] == REQUEST_TYPE] if REQUEST_TYPE != '*' else requests\n",
    "df = df.groupby([\"fg_window\", \"status\"])[\"fg_window\"].count().unstack().fillna(0)\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "fig = plt.figure(figsize=(108, 48))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.axvline(x=(workload_conf[\"duration\"][\"ramp_up\"] * 1000) // PIT_FG_WINDOW_IN_MS,\n",
    "           ls=\"--\", linewidth=5, color=\"green\")\n",
    "ax.axvline(x=((workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"])  * 1000) // PIT_FG_WINDOW_IN_MS,\n",
    "           ls=\"--\", linewidth=5, color=\"green\")\n",
    "ax.set_xticklabels([str(x * 60) for x in range(0, int(df.index.max()) // (60 * (1000 // PIT_FG_WINDOW_IN_MS)) + 1)])\n",
    "df.plot(ax=ax, kind=\"bar\", stacked=True,\n",
    "        title=\"Throughput (requests per %s milliseconds)\" % PIT_FG_WINDOW_IN_MS,\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"Requests (count)\",\n",
    "        color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True, grid=True,\n",
    "        xticks=range(0, int(df.index.max()) + 1, 60 * (1000 // PIT_FG_WINDOW_IN_MS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU5rb4qzdCx7"
   },
   "source": [
    "### Latency Distribution of Successful Requests Excluding Ramping Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzBCF8BedCx7"
   },
   "outputs": [],
   "source": [
    "# [CONFIG] Max latency\n",
    "MAX_LATENCY_IN_S = 10\n",
    "# [CONFIG] Latency bin size\n",
    "LATENCY_BIN_IN_MS = 50\n",
    "\n",
    "df = requests[requests[\"status\"] == \"successful\"]\n",
    "df = df[(df[\"time\"] >= workload_conf[\"duration\"][\"ramp_up\"]) &\n",
    "        (df[\"time\"] <= workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"])]\n",
    "df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca(xlabel=\"Latency (s)\", ylabel=\"Requests (count)\")\n",
    "ax.grid(alpha=0.75)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S))\n",
    "ax.set_ylim((0, 10000))\n",
    "ax.set_xticks(range(0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S + 1, (1000 // LATENCY_BIN_IN_MS)))\n",
    "ax.set_xticklabels([str(s) for s in range(MAX_LATENCY_IN_S + 1)])\n",
    "df[\"latency_bin\"].plot(ax=ax, kind=\"hist\",\n",
    "                       title=\"Latency Distribution of Successful Requests Excluding Ramping Periods\",\n",
    "                       bins=range((1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNzCr2ejdCx7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 24))\n",
    "for (i, (request_type, _)) in enumerate(requests.groupby([\"type\"])):\n",
    "    df = requests[(requests[\"status\"] == \"successful\") & (requests[\"type\"] == request_type)]\n",
    "    df = df[(df[\"time\"] >= workload_conf[\"duration\"][\"ramp_up\"]) &\n",
    "            (df[\"time\"] <= workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"])]\n",
    "    df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "    ax = fig.add_subplot(4, 4, i + 1)\n",
    "    ax.grid(alpha=0.75)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S))\n",
    "    ax.set_ylim((0, 10000))\n",
    "    ax.set_xticks(range(0, (1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S + 1, (1000 // LATENCY_BIN_IN_MS)))\n",
    "    ax.set_xticklabels([str(s) for s in range(MAX_LATENCY_IN_S + 1)])\n",
    "    df[\"latency_bin\"].plot(ax=ax, kind=\"hist\", title=request_type,\n",
    "                           xlabel=\"\", ylabel=\"\",\n",
    "                           bins=range((1000 // LATENCY_BIN_IN_MS) * MAX_LATENCY_IN_S), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyMdkDUYdCx7"
   },
   "source": [
    "### PIT Latency of Successful Requests (1-second window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZVytZnzdCx7"
   },
   "outputs": [],
   "source": [
    "df = requests[requests[\"status\"] == \"successful\"]\n",
    "df = df.groupby([\"window\"])[\"latency\"].agg(PIT_AGGREGATE_FUNC)\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.axvline(x=workload_conf[\"duration\"][\"ramp_up\"],\n",
    "           ls=\"--\", color=\"green\")\n",
    "ax.axvline(x=workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"],\n",
    "           ls=\"--\", color=\"green\")\n",
    "ax.grid(alpha=0.75)\n",
    "df.plot(ax=ax, kind=\"bar\", title=\"PIT Latency of Successful Requests (1-second window)\",\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"Latency (seconds)\",\n",
    "        color=\"purple\", logy=True, grid=True,\n",
    "        xticks=range(0, int(df.index.max()) + 1, 60),\n",
    "        yticks=[0.001, 0.010, 0.100, 1.0, 10.0, 50.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJlCFJwUdCx7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 24))\n",
    "for (i, (request_type, _)) in enumerate(requests.groupby([\"type\"])):\n",
    "    df = requests[(requests[\"status\"] == \"successful\") & (requests[\"type\"] == request_type)]\n",
    "    df = df.groupby([\"window\"])[\"latency\"].agg(PIT_AGGREGATE_FUNC)\n",
    "    df = df.reindex(range(0, int(requests[\"time\"].max()) + 1), fill_value=0)\n",
    "    ax = fig.add_subplot(4, 4, i + 1)\n",
    "    ax.axvline(x=workload_conf[\"duration\"][\"ramp_up\"],\n",
    "               ls=\"--\", color=\"green\")\n",
    "    ax.axvline(x=workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"],\n",
    "               ls=\"--\", color=\"green\")\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"bar\", title=request_type,\n",
    "            xlabel=\"\", ylabel=\"\",\n",
    "            color=\"purple\", logy=True, grid=True,\n",
    "            xticks=range(0, int(requests[\"time\"].max()) + 1, 60),\n",
    "            yticks=[0.001, 0.010, 0.100, 1.0, 10.0, 50.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo40K7vxdCx7"
   },
   "source": [
    "### PIT Latency of Successful Requests (fine-grained window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_V8-07KtdtL"
   },
   "outputs": [],
   "source": [
    "# [CONFIG] Request type or '*' for all\n",
    "REQUEST_TYPE = '*'\n",
    "\n",
    "df = requests[requests[\"type\"] == REQUEST_TYPE] if REQUEST_TYPE != '*' else requests\n",
    "df = df[requests[\"status\"] == \"successful\"]\n",
    "df = df.groupby([\"fg_window\"])[\"latency\"].agg(PIT_AGGREGATE_FUNC)\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "fig = plt.figure(figsize=(108, 48))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.axvline(x=(workload_conf[\"duration\"][\"ramp_up\"] * 1000) // PIT_FG_WINDOW_IN_MS,\n",
    "           ls=\"--\", linewidth=5, color=\"green\")\n",
    "ax.axvline(x=((workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"])  * 1000) // PIT_FG_WINDOW_IN_MS,\n",
    "           ls=\"--\", linewidth=5, color=\"green\")\n",
    "ax.set_xticklabels([str(x * 60) for x in range(0, int(df.index.max()) // (60 * (1000 // PIT_FG_WINDOW_IN_MS)) + 1)])\n",
    "df.plot(ax=ax, kind=\"bar\",\n",
    "        title=\"PIT Latency of Successful Requests (%s-millisecond window)\" % PIT_FG_WINDOW_IN_MS,\n",
    "        xlabel=\"Time (seconds)\", ylabel=\"Latency (seconds)\",\n",
    "        color=\"purple\", logy=True, grid=True,\n",
    "        xticks=range(0, int(df.index.max()) + 1, 60 * (1000 // PIT_FG_WINDOW_IN_MS)),\n",
    "        yticks=[0.001, 0.010, 0.100, 1.0, 10.0, 50.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Event Monitoring Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse tcplife logs\n",
    "conn_to = []\n",
    "for node_hostname in os.listdir(os.path.join(EXPERIMENT_DIR, \"logs\")):\n",
    "    if os.path.isfile(os.path.join(EXPERIMENT_DIR, \"logs\", node_hostname, \"tcplife-bpfcc.tar.gz\")):\n",
    "        tarball = tarfile.open(os.path.join(EXPERIMENT_DIR, \"logs\", node_hostname, \"tcplife-bpfcc.tar.gz\"))\n",
    "        with tarball.extractfile(\"./tcplife-bpfcc.log\") as tcplife_log_file:\n",
    "            reader = csv.DictReader(codecs.getreader(\"utf-8\")(tcplife_log_file))\n",
    "            for row in reader:\n",
    "                if row[\"COMM\"] in (\"uwsgi\", \"nginx\", \"postgres\", \"account_server\", \"follow_server\", \"like_server\", \"post_server\", \"uniquepair_serv\"):\n",
    "                    conn_to.append({\n",
    "                        \"time\": float(row[\"TIME(s)\"]),\n",
    "                        \"comm\": row[\"COMM\"],\n",
    "                        \"addr\": row[\"RADDR\"],\n",
    "                        \"port\": row[\"RPORT\"],\n",
    "                        \"duration\": float(row[\"MS\"])\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "conn_to = pd.DataFrame(conn_to)\n",
    "conn_to[\"fg_window\"] = conn_to.apply(lambda r: range(int(r[\"time\"] * 1000) // TCPLIFE_FG_WINDOW_IN_MS, int((r[\"time\"] + r[\"duration\"] / 1000) * 1000) // TCPLIFE_FG_WINDOW_IN_MS + 1), axis=1)\n",
    "conn_to = conn_to.explode(\"fg_window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Gateway (fine-grained Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Get ports from configuration file\n",
    "\n",
    "df = conn_to\n",
    "df = df[df[\"port\"] == \"8080\"]\n",
    "df = df.groupby([\"fg_window\"])[\"fg_window\"].count()\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "fig = plt.figure(figsize=(108, 48))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.axvline(x=(workload_conf[\"duration\"][\"ramp_up\"] * 1000) // TCPLIFE_FG_WINDOW_IN_MS,\n",
    "           ls=\"--\", linewidth=5, color=\"green\")\n",
    "ax.axvline(x=((workload_conf[\"duration\"][\"total\"] - workload_conf[\"duration\"][\"ramp_down\"])  * 1000) // TCPLIFE_FG_WINDOW_IN_MS,\n",
    "           ls=\"--\", linewidth=5, color=\"green\")\n",
    "ax.set_xticklabels([str(x * 60) for x in range(0, int(df.index.max()) // (60 * (1000 // TCPLIFE_FG_WINDOW_IN_MS)) + 1)])\n",
    "df.plot(ax=ax, kind=\"bar\",\n",
    "        title=\"API Gateway - Number of requests being processed (%s-millisecond window)\" % TCPLIFE_FG_WINDOW_IN_MS,\n",
    "        xlabel=\"Time\", ylabel=\"Requests (count)\",\n",
    "        color=\"black\", grid=True,\n",
    "        xticks=range(0, int(df.index.max()) + 1, 60 * (1000 // TCPLIFE_FG_WINDOW_IN_MS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9RUl5DddCx-"
   },
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eXmMeE1dCx-"
   },
   "source": [
    "### System Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgpAA5nUdCx-",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(yaml.dump(system_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Kw7jVF3dCx-"
   },
   "source": [
    "### Workload Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvNsVldTdCx-"
   },
   "outputs": [],
   "source": [
    "print(yaml.dump(workload_conf))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BuzzBlogExperimentAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
